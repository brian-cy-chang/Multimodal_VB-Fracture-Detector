[general]
seed=23

# train or predict
mode = train
output_path = ./output

# use-specified folder name. If not provided, default name is <model_name>_timestamp
output_folder = 

# specify a model architecture name to use, must be one in joint_fusion or late_fusion
model_name = JointFusion_CNN
use_fine_tuned = False

# path of fine-tune model that must be a .pth file, applicable only if use_fine_tuned = True
# example path = ./output/JointFusion_CNN/model_weights (do not have to add ".pth")
fine_tuned_path =

# name of model.state_dict to save to .pth if mode = train. If not set, default name is <model_name>_<loss_function>_timestamp
save_name = 

[bert]
# discrete or cls
bert_mode = discrete
# if bert_mode = discrete, set max padding length
discrete_max_length_pad = 6
# if preprocess_mode = cls
cls_max_length_pad = 200

# if bert_mode = discrete, must be pickle file
train_discrete_file = 
validation_discrete_file = 
predict_discrete_file = 

train_cls_file = 
validation_cls_file = 
predict_cls_file = 

[vb]
train_path = 
validation_path = 
predict_path = 

[patient]
# must be csv
pt_dem_file = 

[labels]
# must be csv
train_label_file = 
validation_label_file = 
test_label_file = 
groundtruth_file = 

[preprocess]
# onehot or label
encode_mode = onehot

[model]
# bce (binary cross-entropy) or focal
loss_function = bce
batch_size = 4 
# kaiming, xavier, he, or None (leave blank)
weight_init =  
epochs = 200 
# hidden_size = 256
# if none, will use default values 
focal_loss_alpha = 0.25
focal_loss_gamma = 2
learning_rate = 0.001 
weight_decay = 0.01
momentum = 0.9  
threshold = 0.0 
patience = 10
dropout_rate = 0.5
grad_clipping = 1.0